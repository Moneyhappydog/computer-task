"""
æµ‹è¯•Layer 2 - è¯­ä¹‰åˆ†æåŠŸèƒ½
æ”¯æŒä»Layer 1çš„è¾“å‡ºè¯»å–æ•°æ®
"""
import json
import argparse
from pathlib import Path
from src.utils.config import Config
from src.layer1_preprocessing import PDFProcessor
from src.layer2_semantic import DocumentAnalyzer

def test_document_analyzer():
    """æµ‹è¯•æ–‡æ¡£åˆ†æå™¨ï¼ˆè¯­ä¹‰åˆ†æï¼‰"""
    print("\n" + "="*70)
    print("ğŸ§ª æµ‹è¯•æ–‡æ¡£åˆ†æå™¨")
    print("="*70)
    
    # å‡†å¤‡æµ‹è¯•æ–‡æœ¬ï¼ˆMarkdownæ ¼å¼ï¼‰
    test_text = """# Introduction

This is the introduction section.

## Background

Some background information here.

### Prerequisites

- Python 3.8+
- pip installed
- Basic knowledge of APIs

## Installation

Follow these steps:

1. Install the package
2. Configure the API key
3. Run the application

### Code Example

```python
import requests
response = requests.get("https://api.example.com")
print(response.json())
```

## Conclusion

This is the conclusion.
"""
    # åˆ›å»ºåˆ†æå™¨
    analyzer = DocumentAnalyzer(use_ai=False)  # å…ˆä¸ä½¿ç”¨AIåˆ†ç±»å™¨

    # åˆ†ææ–‡æ¡£
    result = analyzer.analyze(test_text)

    # æ˜¾ç¤ºç»“æœ
    print(f"\nâœ… åˆ†æå®Œæˆï¼")
    print(f"  è¯­ä¹‰å—æ•°é‡: {len(result['chunks'])}")
    print(f"\nğŸ“Š ç»Ÿè®¡ä¿¡æ¯:")
    print(f"    æ€»å—æ•°: {result['statistics']['total_chunks']}")
    print(f"    ç±»å‹åˆ†å¸ƒ: {result['statistics']['type_distribution']}")
    print(f"    å¹³å‡ç½®ä¿¡åº¦: {result['statistics']['overall_avg_confidence']:.2f}")
    print(f"    éœ€è¦äººå·¥å®¡æ ¸: {result['statistics']['needs_review']} å—")

    print(f"\nğŸ“‘ è¯­ä¹‰å—åˆ†æç»“æœ:")
    for chunk in result['chunks']:
        indent = "  " * (chunk['level'] - 2)  # H2å¼€å§‹
        print(f"{indent}{'#' * chunk['level']} {chunk['title']}")
        print(f"{indent}  åˆ†ç±»: {chunk['classification']['type']} (ç½®ä¿¡åº¦: {chunk['classification']['confidence']:.2f})")
        print(f"{indent}  å†…å®¹é•¿åº¦: {len(chunk['content'].strip())} å­—ç¬¦")

    return True

def test_from_layer1_output(layer1_output_dir: Path, use_ai: bool = False):
    """ä»Layer 1çš„è¾“å‡ºè¯»å–æ•°æ®å¹¶è¿›è¡Œè¯­ä¹‰åˆ†æ
    
    Args:
        layer1_output_dir: Layer 1çš„è¾“å‡ºç›®å½•
        use_ai: æ˜¯å¦ä½¿ç”¨AIåˆ†ç±»å™¨
        
    Returns:
        bool: æµ‹è¯•æ˜¯å¦é€šè¿‡
    """
    print("\n" + "="*70)
    print("ğŸ§ª ä»Layer 1è¾“å‡ºè¿›è¡Œè¯­ä¹‰åˆ†æ")
    print("="*70)
    
    # ä¼˜å…ˆå°è¯•è¯»å–JSONæ–‡ä»¶ï¼ˆåŒ…å«å®Œæ•´çš„metadataï¼‰
    layer1_result_file = layer1_output_dir / "layer1_result.json"
    metadata = {}
    markdown_content = None
    
    if layer1_result_file.exists():
        print(f"ğŸ“„ è¯»å–Layer 1ç»“æœæ–‡ä»¶: {layer1_result_file.name}")
        with open(layer1_result_file, 'r', encoding='utf-8') as f:
            layer1_result = json.load(f)
        
        if not layer1_result.get('success', False):
            print(f"âŒ Layer 1å¤„ç†å¤±è´¥: {layer1_result.get('error')}")
            return False
        
        markdown_content = layer1_result.get('markdown')
        metadata = layer1_result.get('metadata', {})
        print(f"âœ… ä»JSONè¯»å–æˆåŠŸ: {len(markdown_content)} å­—ç¬¦")
        print(f"   ä½¿ç”¨æ–¹æ³•: {metadata.get('method', 'N/A')}")
        print(f"   é¡µæ•°: {metadata.get('pages', 'N/A')}")
    else:
        # å¦‚æœæ²¡æœ‰JSONï¼Œå°è¯•è¯»å–Markdownæ–‡ä»¶
        md_files = list(layer1_output_dir.glob("*.md"))
        if not md_files:
            print(f"âŒ æœªæ‰¾åˆ°Layer 1çš„è¾“å‡ºæ–‡ä»¶ï¼ˆJSONæˆ–Markdownï¼‰: {layer1_output_dir}")
            return False
        
        markdown_file = md_files[0]
        print(f"ğŸ“„ è¯»å–Layer 1çš„Markdownæ–‡ä»¶: {markdown_file.name}")
        
        with open(markdown_file, 'r', encoding='utf-8') as f:
            markdown_content = f.read()
        
        print(f"âœ… ä»Markdownè¯»å–æˆåŠŸ: {len(markdown_content)} å­—ç¬¦")
        print(f"   æç¤º: æœªæ‰¾åˆ°metadataä¿¡æ¯ï¼ˆJSONæ–‡ä»¶ä¸å­˜åœ¨ï¼‰")
    
    # åˆ›å»ºLayer 2è¾“å‡ºç›®å½•
    output_dir = layer1_output_dir.parent / "layer2"
    output_dir.mkdir(parents=True, exist_ok=True)
    
    # ä½¿ç”¨Layer 2è¿›è¡Œè¯­ä¹‰åˆ†æ
    print(f"\n2ï¸âƒ£  ä½¿ç”¨Layer 2è¿›è¡Œè¯­ä¹‰åˆ†æ...")
    analyzer = DocumentAnalyzer(use_ai=use_ai)
    layer2_result = analyzer.analyze(markdown_content, metadata)
    
    # ä¿å­˜Layer 2ç»“æœ
    layer2_result_file = output_dir / "layer2_result.json"
    with open(layer2_result_file, 'w', encoding='utf-8') as f:
        json.dump(layer2_result, f, ensure_ascii=False, indent=2)
    
    # ä¿å­˜è¯­ä¹‰å—æ–‡æœ¬
    chunks_file = output_dir / "layer2_chunks.txt"
    with open(chunks_file, 'w', encoding='utf-8') as f:
        for chunk in layer2_result['chunks']:
            f.write(f"\n\n{'='*70}\n")
            f.write(f"{'#' * chunk['level']} {chunk['title']}\n")
            f.write(f"ç±»å‹: {chunk['classification']['type']} (ç½®ä¿¡åº¦: {chunk['classification']['confidence']:.2f})\n")
            f.write(f"{'='*70}\n\n")
            f.write(chunk['content'])
    
    # æ˜¾ç¤ºç»“æœ
    print(f"âœ… è¯­ä¹‰åˆ†æå®Œæˆï¼")
    print(f"   è¯­ä¹‰å—æ•°é‡: {len(layer2_result['chunks'])}")
    print(f"   ç±»å‹åˆ†å¸ƒ: {layer2_result['statistics']['type_distribution']}")
    print(f"   å¹³å‡ç½®ä¿¡åº¦: {layer2_result['statistics']['overall_avg_confidence']:.2f}")
    print(f"   éœ€è¦äººå·¥å®¡æ ¸: {layer2_result['statistics']['needs_review']} å—")
    print(f"   è¾“å‡ºå·²ä¿å­˜åˆ°: {output_dir}")
    
    # æ˜¾ç¤ºå‰å‡ ä¸ªè¯­ä¹‰å—çš„åˆ†æç»“æœ
    print(f"\nğŸ“‘ å‰5ä¸ªè¯­ä¹‰å—åˆ†æ:")
    for chunk in layer2_result['chunks'][:5]:
        print(f"\n  {'#' * chunk['level']} {chunk['title']}")
        print(f"    åˆ†ç±»: {chunk['classification']['type']} (ç½®ä¿¡åº¦: {chunk['classification']['confidence']:.2f})")
        print(f"    å†…å®¹é¢„è§ˆ: {chunk['content'].strip()[:100]}...")
    
    return True


def test_pdf_integration():
    """æµ‹è¯•PDFåˆ°è¯­ä¹‰åˆ†æçš„å®Œæ•´æµç¨‹"""
    print("\n" + "="*70)
    print("ğŸ§ª æµ‹è¯•PDFåˆ°è¯­ä¹‰åˆ†æçš„å®Œæ•´æµç¨‹")
    print("="*70)

    # è¯»å–æµ‹è¯•PDFæ–‡ä»¶
    test_pdf = Path(r"d:\codeC\VsCodeP\dita-converter\uploads\2023CVPR-CoMFormer.pdf")

    if not test_pdf.exists():
        print("âš ï¸  æœªæ‰¾åˆ°æµ‹è¯•PDFæ–‡ä»¶ï¼Œè·³è¿‡æµ‹è¯•")
        return False

    print(f"ğŸ“„ æµ‹è¯•æ–‡ä»¶: {test_pdf.name}")
    
    # Step 1: ä½¿ç”¨Layer 1æå–PDFæ–‡æœ¬ä¸ºMarkdown
    print("\n1ï¸âƒ£  ä½¿ç”¨Layer 1æå–PDFæ–‡æœ¬...")
    processor = PDFProcessor(use_marker=True, use_ocr=True)
    layer1_result = processor.process(test_pdf)
    
    if not layer1_result['success']:
        print(f"âŒ Layer 1å¤„ç†å¤±è´¥: {layer1_result.get('error')}")
        return False
    
    markdown_content = layer1_result['markdown']
    print(f"âœ… æå–å®Œæˆ: {len(markdown_content)} å­—ç¬¦")
    print(f"   ä½¿ç”¨æ–¹æ³•: {layer1_result['metadata']['method']}")
    print(f"   é¡µæ•°: {layer1_result['metadata']['pages']}")

    # Step 2: ä½¿ç”¨Layer 2è¿›è¡Œè¯­ä¹‰åˆ†æ
    print("\n2ï¸âƒ£  ä½¿ç”¨Layer 2è¿›è¡Œè¯­ä¹‰åˆ†æ...")
    analyzer = DocumentAnalyzer(use_ai=False)  # å…ˆä¸ä½¿ç”¨AIåˆ†ç±»å™¨
    layer2_result = analyzer.analyze(markdown_content, layer1_result['metadata'])
    
    # æ˜¾ç¤ºç»“æœ
    print(f"âœ… è¯­ä¹‰åˆ†æå®Œæˆï¼")
    print(f"   è¯­ä¹‰å—æ•°é‡: {len(layer2_result['chunks'])}")
    print(f"   ç±»å‹åˆ†å¸ƒ: {layer2_result['statistics']['type_distribution']}")
    
    # æ˜¾ç¤ºå‰å‡ ä¸ªè¯­ä¹‰å—çš„åˆ†æç»“æœ
    print(f"\nğŸ“‘ å‰5ä¸ªè¯­ä¹‰å—åˆ†æ:")
    for chunk in layer2_result['chunks'][:5]:
        print(f"\n  {'#' * chunk['level']} {chunk['title']}")
        print(f"    åˆ†ç±»: {chunk['classification']['type']} (ç½®ä¿¡åº¦: {chunk['classification']['confidence']:.2f})")
        print(f"    å†…å®¹é¢„è§ˆ: {chunk['content'].strip()[:100]}...")

    return True

def test_with_ai_classifier():
    """æµ‹è¯•ä½¿ç”¨AIåˆ†ç±»å™¨çš„æ–‡æ¡£åˆ†æï¼ˆå¯é€‰ï¼‰"""
    print("\n" + "="*70)
    print("ğŸ§ª æµ‹è¯•ä½¿ç”¨AIåˆ†ç±»å™¨çš„æ–‡æ¡£åˆ†æ")
    print("="*70)

    try:
        # å‡†å¤‡ç®€çŸ­çš„æµ‹è¯•æ–‡æœ¬
        test_text = """## Installation Guide

Follow these steps to install the software:

1. Download the installation package from our website
2. Run the installer as administrator
3. Follow the on-screen instructions
4. Restart your computer after installation

## Troubleshooting

If you encounter any issues, try the following:
- Check if your system meets the requirements
- Ensure you have administrator privileges
- Disable antivirus software temporarily
"""
        
        print("ğŸ“ æµ‹è¯•æ–‡æœ¬å‡†å¤‡å®Œæˆ")
        
        # åˆ›å»ºåˆ†æå™¨ï¼ˆå¯ç”¨AIåˆ†ç±»å™¨ï¼‰
        analyzer = DocumentAnalyzer(use_ai=True)
        
        # åˆ†ææ–‡æ¡£
        result = analyzer.analyze(test_text)
        
        # æ˜¾ç¤ºç»“æœ
        print(f"\nâœ… AIåˆ†æå®Œæˆï¼")
        print(f"   è¯­ä¹‰å—æ•°é‡: {len(result['chunks'])}")
        
        for chunk in result['chunks']:
            print(f"\n  {'#' * chunk['level']} {chunk['title']}")
            print(f"    AIåˆ†ç±»: {chunk['classification']['type']} (ç½®ä¿¡åº¦: {chunk['classification']['confidence']:.2f})")
            print(f"    ç‰¹å¾: {list(chunk['features'].keys())[:5]}...")
        
        print("\nâœ… AIåˆ†ç±»å™¨æµ‹è¯•é€šè¿‡ï¼")
        return True
        
    except Exception as e:
        print(f"âš ï¸ AIåˆ†ç±»å™¨æµ‹è¯•è·³è¿‡: {e}")
        print("   è¿™å¯èƒ½æ˜¯å› ä¸ºæ²¡æœ‰é…ç½®AI APIå¯†é’¥æˆ–ç½‘ç»œé—®é¢˜")
        return False

if __name__ == "__main__":
    print("ğŸ§ª å¼€å§‹æµ‹è¯• Layer 2 åŠŸèƒ½...\n")
    
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    parser = argparse.ArgumentParser(description='æµ‹è¯•Layer 2 - è¯­ä¹‰åˆ†æåŠŸèƒ½')
    parser.add_argument('--layer1-output', type=str, help='Layer 1çš„è¾“å‡ºç›®å½•è·¯å¾„')
    parser.add_argument('--use-ai', action='store_true', help='æ˜¯å¦ä½¿ç”¨AIåˆ†ç±»å™¨')
    parser.add_argument('--full-test', action='store_true', help='è¿è¡Œå®Œæ•´æµ‹è¯•ï¼ˆåŒ…æ‹¬PDFå¤„ç†ï¼‰')
    
    args = parser.parse_args()
    
    success = True
    
    # å¦‚æœæŒ‡å®šäº†Layer 1è¾“å‡ºç›®å½•ï¼Œä»è¯¥ç›®å½•è¯»å–æ•°æ®
    if args.layer1_output:
        layer1_output_dir = Path(args.layer1_output)
        if not layer1_output_dir.exists():
            print(f"âŒ Layer 1è¾“å‡ºç›®å½•ä¸å­˜åœ¨: {layer1_output_dir}")
            success = False
        else:
            success = test_from_layer1_output(layer1_output_dir, use_ai=args.use_ai)
    
    # å¦åˆ™è¿è¡Œæ ‡å‡†æµ‹è¯•
    elif args.full_test:
        # æµ‹è¯•1: æ–‡æ¡£åˆ†æå™¨ï¼ˆåŸºç¡€åŠŸèƒ½ï¼‰
        test_document_analyzer()

        # æµ‹è¯•2: PDFåˆ°è¯­ä¹‰åˆ†æçš„å®Œæ•´æµç¨‹
        test_pdf_integration()

        # æµ‹è¯•3: AIåˆ†ç±»å™¨ï¼ˆå¯é€‰ï¼‰
        print("\n" + "="*70)
        print("âš ï¸  å‡†å¤‡æµ‹è¯•AIåˆ†ç±»å™¨åŠŸèƒ½")
        print("="*70)

        user_input = input("æ˜¯å¦ç»§ç»­æµ‹è¯•AIåˆ†ç±»å™¨ï¼Ÿ(y/n): ").strip().lower()

        if user_input == 'y':
            test_with_ai_classifier()
        else:
            print("â­ï¸  è·³è¿‡AIåˆ†ç±»å™¨æµ‹è¯•")
    else:
        print("ä½¿ç”¨æ–¹æ³•:")
        print("  ä»Layer 1è¾“å‡ºè¯»å–: python test_layer2.py --layer1-output <layer1è¾“å‡ºç›®å½•>")
        print("  è¿è¡Œå®Œæ•´æµ‹è¯•:      python test_layer2.py --full-test")
        print("  ä½¿ç”¨AIåˆ†ç±»å™¨:      æ·»åŠ  --use-ai å‚æ•°")
        print("\nç¤ºä¾‹:")
        print("  python test_layer2.py --layer1-output data/output/2023CVPR-CoMFormer/layer1")
        print("  python test_layer2.py --layer1-output data/output/2023CVPR-CoMFormer/layer1 --use-ai")
        success = False

    print("\n" + "="*70)
    if success:
        print("âœ… Layer 2 æµ‹è¯•å®Œæˆï¼")
    else:
        print("âŒ Layer 2 æµ‹è¯•å¤±è´¥æˆ–æœªè¿è¡Œï¼")
    print("="*70)