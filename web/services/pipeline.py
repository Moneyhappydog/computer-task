"""
å¤„ç†æµæ°´çº¿
åè°ƒå››å±‚æ¶æ„çš„å®Œæ•´å¤„ç†æµç¨‹
"""
from pathlib import Path
from typing import Dict, Any, Callable
import logging
from datetime import datetime

from src.layer1_preprocessing import FileRouter
from src.layer2_semantic import DocumentAnalyzer
from src.layer3_dita_conversion import DITAConverter
from src.layer4_quality_assurance import QAManager

logger = logging.getLogger(__name__)

class ProcessingPipeline:
    """å®Œæ•´å¤„ç†æµæ°´çº¿"""
    
    def __init__(self):
        """åˆå§‹åŒ–æµæ°´çº¿"""
        logger.info("ğŸ”§ åˆå§‹åŒ–å¤„ç†æµæ°´çº¿...")
        
        # åˆå§‹åŒ–å››å±‚
        self.layer1 = FileRouter()
        self.layer2 = DocumentAnalyzer(use_ai=True)
        self.layer3 = DITAConverter(use_ai=True, max_fix_iterations=3)
        self.layer4 = QAManager(use_dita_ot=False, use_ai_repair=True, max_iterations=3)
        
        logger.info("âœ… å¤„ç†æµæ°´çº¿åˆå§‹åŒ–å®Œæˆ")
    
    def process(
        self,
        input_file: Path,
        output_dir: Path,
        progress_callback: Callable[[str, int, Dict], None] = None
    ) -> Dict[str, Any]:
        """
        æ‰§è¡Œå®Œæ•´å¤„ç†æµç¨‹
        
        Args:
            input_file: è¾“å…¥æ–‡ä»¶è·¯å¾„
            output_dir: è¾“å‡ºç›®å½•
            progress_callback: è¿›åº¦å›è°ƒå‡½æ•°(stage, progress, data)
            
        Returns:
            å¤„ç†ç»“æœ
        """
        logger.info(f"ğŸš€ å¼€å§‹å¤„ç†: {input_file.name}")
        
        result = {
            'success': False,
            'input_file': str(input_file),
            'start_time': datetime.now().isoformat(),
            'layers': {},
            'final_output': None,
            'errors': []
        }
        
        try:
            # ========== Layer 1: é¢„å¤„ç† ==========
            self._update_progress(progress_callback, 'layer1', 0, {
                'message': 'å¼€å§‹é¢„å¤„ç†ï¼Œè¯»å–æ–‡ä»¶...'
            })
            
            layer1_result = self.layer1.process_file(input_file)
            result['layers']['layer1'] = layer1_result
            
            if not layer1_result['success']:
                raise Exception(f"Layer 1 å¤±è´¥: {layer1_result.get('error')}")
            
            markdown_content = layer1_result['markdown']
            
            # æ·»åŠ ç½®ä¿¡åº¦ä¿¡æ¯
            layer1_result['confidence'] = layer1_result.get('confidence', 0.8)
            
            self._update_progress(progress_callback, 'layer1', 100, {
                'message': 'âœ… é¢„å¤„ç†å®Œæˆ',
                'markdown_length': len(markdown_content),
                'file_type': layer1_result['file_type']
            })
            
            # ========== Layer 2: è¯­ä¹‰åˆ†æ ==========
            self._update_progress(progress_callback, 'layer2', 0, {
                'message': 'å¼€å§‹è¯­ä¹‰åˆ†æï¼Œæ–‡æœ¬åˆ†å—...'
            })
            
            layer2_result = self.layer2.analyze(markdown_content)
            result['layers']['layer2'] = layer2_result
            
            chunks = layer2_result['chunks']
            
            # ç¡®å®šæ–‡æ¡£ç±»å‹ï¼ˆä½¿ç”¨æœ€ä¸»è¦çš„ç±»å‹ï¼‰
            type_dist = layer2_result['statistics']['type_distribution']
            if type_dist:
                primary_type = max(type_dist.items(), key=lambda x: x[1])[0]
            else:
                primary_type = "Concept"  # é»˜è®¤ç±»å‹
            
            # å¦‚æœæ²¡æœ‰chunksï¼Œä½¿ç”¨åŸå§‹å†…å®¹ä½œä¸ºå•ä¸ªchunk
            if not chunks:
                chunks = [{
                    'id': 'single_chunk',
                    'content': markdown_content,
                    'title': layer2_result.get('title', 'Untitled Document'),
                    'type': primary_type,
                    'classification': {'type': primary_type, 'confidence': 0.8}
                }]
            else:
                # ç¡®ä¿æ¯ä¸ªchunkéƒ½æœ‰typeå­—æ®µ
                for chunk in chunks:
                    if 'type' not in chunk and 'classification' in chunk:
                        chunk['type'] = chunk['classification']['type']
                    elif 'type' not in chunk:
                        chunk['type'] = primary_type
            
            self._update_progress(progress_callback, 'layer2', 100, {
                'message': 'âœ… è¯­ä¹‰åˆ†æå®Œæˆ',
                'total_chunks': len(chunks),
                'type_distribution': layer2_result['statistics']['type_distribution']
            })
            
            # ========== Layer 3: DITAè½¬æ¢ ==========
            self._update_progress(progress_callback, 'layer3', 0, {
                'message': f'å¼€å§‹DITAè½¬æ¢ï¼Œå¤„ç† {len(chunks)} ä¸ªå—...'
            })
            
            # å‡†å¤‡è½¬æ¢æ•°æ®
            conversion_chunks = []
            for chunk in chunks:
                conversion_chunks.append({
                    'content': chunk['content'],
                    'title': chunk['title'],
                    'type': chunk['classification']['type'],
                    'metadata': {
                        'confidence': chunk['classification']['confidence'],
                        'chunk_id': chunk['id']
                    }
                })
            
            layer3_result = self.layer3.convert_batch(
                conversion_chunks,
                output_dir=output_dir / 'dita_drafts'
            )
            
            result['layers']['layer3'] = {
                'total': layer3_result['total'],
                'success': layer3_result['success'],
                'failed': layer3_result['failed'],
                'success_rate': layer3_result['success_rate']
            }
            
            self._update_progress(progress_callback, 'layer3', 100, {
                'message': f'âœ… DITAè½¬æ¢å®Œæˆ ({layer3_result["success"]}/{layer3_result["total"]})',
                'success_count': layer3_result['success']
            })
            
            # ========== Layer 4: è´¨é‡ä¿è¯ ==========
            self._update_progress(progress_callback, 'layer4', 0, {
                'message': 'å¼€å§‹è´¨é‡ä¿è¯ï¼ŒéªŒè¯DITAæ–‡æ¡£...'
            })
            
            # å‡†å¤‡QAæ•°æ®
            qa_documents = []
            layer3_output_dir = output_dir / 'dita_drafts'
            
            for i, conv_result in enumerate(layer3_result['results'], 1):
                if not conv_result['success']:
                    continue
                
                # è·å–æ–‡æ¡£è·¯å¾„
                content_type = conv_result['content_type']
                title = conv_result['title']
                safe_title = "".join(c if c.isalnum() else '_' for c in title)[:50]
                filename = f"{i:03d}_{content_type.lower()}_{safe_title}.dita"
                dita_file_path = layer3_output_dir / filename
                
                # è¯»å–DITAæ–‡ä»¶
                try:
                    with open(dita_file_path, 'r', encoding='utf-8') as f:
                        dita_xml = f.read()
                except Exception as e:
                    logger.error(f"âŒ è¯»å–DITAæ–‡ä»¶å¤±è´¥: {e}")
                    continue
                
                qa_documents.append({
                    'xml': dita_xml,
                    'type': content_type,
                    'metadata': {
                        'layer1_confidence': layer1_result.get('confidence', 0.0),
                        'layer2_confidence': layer2_result['statistics']['overall_avg_confidence'],
                        'layer3_iterations': conv_result['metadata']['iterations'],
                        'title': title,
                        'filename': filename
                    }
                })
            
            if qa_documents:
                layer4_result = self.layer4.process_batch(
                    qa_documents,
                    output_dir=output_dir / 'final_dita'
                )
                
                result['layers']['layer4'] = {
                    'total': layer4_result['total'],
                    'success': layer4_result['success'],
                    'failed': layer4_result['failed'],
                    'success_rate': layer4_result['success_rate'],
                    'avg_quality_score': layer4_result['summary']['quality_scores']['avg_overall_quality']
                }
                
                self._update_progress(progress_callback, 'layer4', 100, {
                    'message': f'âœ… è´¨é‡ä¿è¯å®Œæˆ ({layer4_result["success"]}/{layer4_result["total"]})',
                    'avg_quality': layer4_result['summary']['quality_scores']['avg_overall_quality']
                })
            else:
                # æ²¡æœ‰å¯å¤„ç†çš„DITAæ–‡æ¡£
                self._update_progress(progress_callback, 'layer4', 100, {
                    'message': 'âœ… è´¨é‡ä¿è¯å®Œæˆ (æ— DITAæ–‡æ¡£å¯å¤„ç†)',
                    'avg_quality': 0.0
                })
                
                result['layers']['layer4'] = {
                    'total': 0,
                    'success': 0,
                    'failed': 0,
                    'success_rate': 0.0,
                    'avg_quality_score': 0.0
                }
            
            # ========== å®Œæˆ ==========
            result['success'] = True
            result['end_time'] = datetime.now().isoformat()
            result['final_output'] = str(output_dir / 'final_dita')
            
            self._update_progress(progress_callback, 'complete', 100, {
                'message': 'ğŸ‰ æ‰€æœ‰å¤„ç†å®Œæˆï¼',
                'output_dir': str(output_dir / 'final_dita')
            })
            
            logger.info(f"âœ… å¤„ç†å®Œæˆ: {input_file.name}")
            
        except Exception as e:
            logger.error(f"âŒ å¤„ç†å¤±è´¥: {e}", exc_info=True)
            result['errors'].append(str(e))
            
            self._update_progress(progress_callback, 'error', 0, {
                'message': f'âŒ å¤„ç†å¤±è´¥: {str(e)}'
            })
        
        return result
    
    def _update_progress(
        self,
        callback: Callable,
        stage: str,
        progress: int,
        data: Dict
    ):
        """æ›´æ–°è¿›åº¦"""
        if callback:
            callback(stage, progress, data)


# å…¨å±€å•ä¾‹
_pipeline = None

def get_pipeline() -> ProcessingPipeline:
    """è·å–æµæ°´çº¿å•ä¾‹"""
    global _pipeline
    if _pipeline is None:
        _pipeline = ProcessingPipeline()
    return _pipeline